{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicuai/Book-SD-MasterGuide/blob/main/ComfyJapan_LTX2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHeV1M2PQdoX"
      },
      "source": [
        "# [ComfyJapan] ComfyUI LTX-2 å‹•ç”»ç”Ÿæˆ\n",
        "\n",
        "## ğŸš€ æ¦‚è¦\n",
        "\n",
        "Lightricksç¤¾ã®æœ€æ–°å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ« **LTX-2** ã‚’ Google Colab ã§é‹ç”¨ã™ã‚‹ãŸã‚ã®çµ±åˆç’°å¢ƒã§ã™ã€‚ãƒãƒ¼ã‚ºåˆ¶å¾¡ï¼ˆPose to Videoï¼‰ ã¨ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆText to Videoï¼‰ ã®ä¸¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«å®Œå…¨å¯¾å¿œã—ã€24æ™‚é–“ç¨¼åƒã‚’æƒ³å®šã—ãŸã€Œè‡ªå·±ä¿®å¾©æ©Ÿèƒ½ã€ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "### ğŸ› ï¸ æŠ€è¡“è§£èª¬ã¨æ¨å¥¨ç’°å¢ƒ\n",
        "\n",
        "* **æ¨å¥¨GPU**: **L4 GPU (22.5GB)** ä»¥ä¸Šã€‚ç”Ÿæˆé€Ÿåº¦ã¨å®‰å®šæ€§ã®é¢ã‹ã‚‰ **A100 / H100** ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n",
        "\n",
        "* **ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–**: L4/T4 GPUã§ã¯VRAMå®¹é‡ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆ19B + 12Bï¼‰ã«å¯¾ã—ã¦ã‚·ãƒ“ã‚¢ãªãŸã‚ã€è‡ªå‹•çš„ã«ãƒ¡ãƒ¢ãƒªç¯€ç´„ãƒ¢ãƒ¼ãƒ‰ï¼ˆ`--lowvram`ï¼‰ã‚’é©ç”¨ã—ã¾ã™ã€‚\n",
        "\n",
        "å‚è€ƒ\n",
        "\n",
        "| GPU | RAM | VRAM | Storage | å‚™è€ƒ |\n",
        "|-----|-----|------|---------|------|\n",
        "| T4 | 12GB | 15GB | 112GB | å‹•ä½œå¯èƒ½ï¼ˆåˆ¶é™ã‚ã‚Šï¼‰ |\n",
        "| L4 | 53GB | 22.5GB | 112GB | æ¨å¥¨æœ€å°æ§‹æˆ |\n",
        "| A100/H100 | 83GB | 40GB+ | 112GB | å¼·ãæ¨å¥¨ |\n",
        "\n",
        "\n",
        "\n",
        "* **è‡ªå·±ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯**:\n",
        "* **ãƒ¢ãƒ‡ãƒ«é…ç½®**: Gemma 3IT ç­‰ã®è¤‡é›‘ãªéšå±¤ãƒ¢ãƒ‡ãƒ«ã‚’ ComfyUI èªè­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸è‡ªå‹•æ•´ç†ã—ã¾ã™ã€‚\n",
        "* **è‡ªå‹•å†èµ·å‹•**: ã‚µãƒ¼ãƒãƒ¼ãŒãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOMï¼‰ãªã©ã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãŸå ´åˆã€ã‚¹ãƒ¬ãƒƒãƒ‰ãŒãã‚Œã‚’æ¤œçŸ¥ã—ã¦ Discord ã«å ±å‘Šã—ã€è‡ªå‹•çš„ã«ãƒ—ãƒ­ã‚»ã‚¹ã‚’å†ç«‹ã¡ä¸Šã’ã—ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "### ğŸ“‹ äº‹å‰æº–å‚™\n",
        "\n",
        "1. **HuggingFace**: [LTX-2 Repository](https://huggingface.co/Lightricks/LTX-2) ã§åˆ©ç”¨è¨±è«¾ã‚’æ¸ˆã¾ã›ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã® `HF_TOKEN` ã‚’ã€Colabã®ã€ŒğŸ”‘ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "2. **Discord**: é€šçŸ¥ç”¨ Webhook URL ã‚’ `DISCORD_URL` ã¨ã—ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrj4C9pxNS_i"
      },
      "source": [
        "# ğŸ¥šå„ç¨®ãƒ¢ãƒ‡ãƒ«ã®DL ï¼† ComfyUIã®èµ·å‹•ğŸ£\n",
        "##ï¼œã¯ã˜ã‚ã‚‹å‰ã®æº–å‚™ï¼\n",
        "### â¶ Google Colab ã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€ã« `HF_TOKEN` ã¨ `DISCORD_URL` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "### â·ï¼ˆâ–¶ï¼‰ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦èµ·å‹•ã€‚å®Œäº†ã™ã‚‹ã¨ Discord ã«é€šçŸ¥ãŒå±Šãã¾ã™ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "æ·»ä»˜ã®å…¬å¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€éš›ã«ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n",
        "\n",
        "t2vã‚°ãƒ©ãƒ•ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n",
        "\n",
        "checkpoints / ltx-2-19b-distilled.safetensors\n",
        "\n",
        "latent_upscale_models / ltx-2-spatial-upscaler-x2-1.0.safetensors\n",
        "\n",
        "loras / ltx-2-19b-lora-camera-control-dolly-left.safetensors\n",
        "\n",
        "i2vã‚°ãƒ©ãƒ•ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n",
        "\n",
        "checkpoints / ltx-2-19b-distilled.safetensors\n",
        "\n",
        "latent_upscale_models / ltx-2-spatial-upscaler-x2-1.0.safetensors\n",
        "\n",
        "loras / ltx-2-19b-lora-camera-control-dolly-left.safetensors\n",
        "\n",
        "ğŸ“‚ ComfyUI/\n",
        "â””â”€â”€ ğŸ“‚ models/\n",
        "    â”œâ”€â”€ ğŸ“‚ checkpoints/\n",
        "    â”‚      â””â”€â”€ ltx-2-19b-distilled.safetensors\n",
        "    â”œâ”€â”€ ğŸ“‚ text_encoders/\n",
        "    â”‚      â””â”€â”€ gemma_3_12B_it.safetensors\n",
        "    â”œâ”€â”€ ğŸ“‚ loras/\n",
        "    â”‚      â””â”€â”€ ltx-2-19b-lora-camera-control-dolly-left.safetensors\n",
        "    â””â”€â”€ ğŸ“‚ latent_upscale_models/\n",
        "           â””â”€â”€ ltx-2-spatial-upscaler-x2-1.0.safetensors\n",
        "\n"
      ],
      "metadata": {
        "id": "x0SP8o8qklWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp2-pOzeK-GF"
      },
      "outputs": [],
      "source": [
        "# @markdown # ğŸ‘ˆ æœ€çµ‚çµ±åˆãƒœã‚¿ãƒ³ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ãƒ»è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ä»˜ï¼‰\n",
        "# @markdown ---\n",
        "# @markdown â€» Secretsè¨­å®šã«å¤±æ•—ã—ã¦ã‚‚ã€ComfyUIã¯èµ·å‹•ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ã¾ã—ãŸã€‚\n",
        "\n",
        "import os, socket, time, threading, requests, shutil, subprocess, re, sys\n",
        "from collections import deque\n",
        "from google.colab import userdata, output\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ”‘ 1. è¨­å®š & é€šçŸ¥æ©Ÿèƒ½ (ã‚¨ãƒ©ãƒ¼å›é¿å‹)\n",
        "# ==========================================\n",
        "def get_colab_secret(key):\n",
        "    try:\n",
        "        return userdata.get(key)\n",
        "    except:\n",
        "        print(f\"âš ï¸ è­¦å‘Š: ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ '{key}' ã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚Secretsã‚¿ãƒ–ã§è¨±å¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "        return None\n",
        "\n",
        "webhook_url = get_colab_secret('DISCORD_URL')\n",
        "hf_token = get_colab_secret('HF_TOKEN')\n",
        "if hf_token: os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "def send_discord(msg):\n",
        "    if webhook_url:\n",
        "        try: requests.post(webhook_url, json={\"content\": msg}, timeout=10)\n",
        "        except: pass\n",
        "\n",
        "# GPUæƒ…å ±ã®å–å¾—\n",
        "try:\n",
        "    gpu_full = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=name,memory.total\", \"--format=csv,noheader\"]).decode().strip()\n",
        "    gpu_name = gpu_full.split(\",\")[0]\n",
        "except: gpu_full = gpu_name = \"GPU\"\n",
        "\n",
        "# ğŸš€ èµ·å‹•é€šçŸ¥\n",
        "send_discord(f\"ğŸ›¡ï¸ **LTX-2 é˜²è¡›ãƒ¢ãƒ¼ãƒ‰èµ·å‹•**\\nğŸ’» GPU: `{gpu_full}`\\nğŸ’¾ ç©ºãå®¹é‡: `{shutil.disk_usage('/')[2] // (2**30)}GB`\")\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ“ 2. ç’°å¢ƒæ§‹ç¯‰ & æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯\n",
        "# ==========================================\n",
        "%cd /content\n",
        "if not os.path.exists(\"ComfyUI/main.py\"):\n",
        "    print(\"ğŸ“¥ ComfyUI ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "    subprocess.run([\"git\", \"clone\", \"https://github.com/Comfy-Org/ComfyUI.git\", \"-q\"])\n",
        "\n",
        "print(\"ğŸ› ï¸ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç‚¹æ¤œä¸­...\")\n",
        "!pip install -q torchsde==0.2.6 onnxruntime-gpu comfy-cli requests spandrel av albumentations opencv-python\n",
        "%cd /content/ComfyUI\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ“¥ 3. çµ¶å¯¾ã«å¤–ã•ãªã„ã€Œå¿…é ˆ4ãƒ•ã‚¡ã‚¤ãƒ«ã€\n",
        "# ==========================================\n",
        "print(\"ğŸ›¡ï¸ å¿…é ˆãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèªä¸­...\")\n",
        "\n",
        "def safe_download(repo, file, folder, size_gb):\n",
        "    dest = os.path.join(\"/content/ComfyUI\", folder, file)\n",
        "    os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
        "    if not os.path.exists(dest):\n",
        "        free = shutil.disk_usage('/')[2] // (2**30)\n",
        "        if free > (size_gb + 2):\n",
        "            print(f\"ğŸ“¦ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹({size_gb}GB): {file}\")\n",
        "            subprocess.run([\"hf\", \"download\", repo, file, \"--local-dir\", os.path.join(\"/content/ComfyUI\", folder), \"--quiet\"])\n",
        "        else:\n",
        "            print(f\"ğŸš¨ ã‚¹ã‚­ãƒƒãƒ—: {file} (æ®‹ã‚Šå®¹é‡ {free}GB ä¸è¶³)\")\n",
        "\n",
        "# å¿…é ˆâ‘ ï¼šLTX-2 FP8 æœ¬ä½“ (19GB)\n",
        "safe_download(\"Lightricks/LTX-2\", \"ltx-2-19b-dev-fp8.safetensors\", \"models/checkpoints\", 19)\n",
        "\n",
        "# å¿…é ˆâ‘¡ï¼šGemma 3 IT (12GB) [cite: 66, 202]\n",
        "safe_download(\"Comfy-Org/ltx-2\", \"split_files/text_encoders/gemma_3_12B_it.safetensors\", \"models/text_encoders\", 12)\n",
        "g_path = \"models/text_encoders/split_files/text_encoders/gemma_3_12B_it.safetensors\"\n",
        "if os.path.exists(g_path): shutil.move(g_path, \"models/text_encoders/gemma_3_12B_it.safetensors\")\n",
        "\n",
        "# å¿…é ˆâ‘¢ï¼šSpatial Upscaler (1GB) [cite: 291, 292]\n",
        "safe_download(\"Lightricks/LTX-2\", \"ltx-2-spatial-upscaler-x2-1.0.safetensors\", \"models/latent_upscale_models\", 1)\n",
        "\n",
        "# å¿…é ˆâ‘£ï¼šDistilled LoRA (1GB)\n",
        "safe_download(\"Lightricks/LTX-2\", \"ltx-2-19b-distilled-lora-384.safetensors\", \"models/loras\", 1)\n",
        "\n",
        "# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒ‰ã®æœ€çµ‚ç‚¹æ¤œ\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "for url in [\"https://github.com/Comfy-Org/ComfyUI-Manager\", \"https://github.com/Lightricks/ComfyUI-LTXVideo\"]:\n",
        "    name = url.split(\"/\")[-1]\n",
        "    if not os.path.exists(name): subprocess.run([\"git\", \"clone\", url, \"-q\"])\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ“¡ 4. URLç™ºè¡Œ & ãƒ­ã‚°ç›£è¦–\n",
        "# ==========================================\n",
        "def monitor_ready(port):\n",
        "    while True:\n",
        "        try:\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "                url = output.eval_js(f'google.colab.kernel.proxyPort({port})')\n",
        "                msg = f\"ğŸ‰ **ComfyUI Ready!**\\nğŸ’» GPU: `{gpu_name}`\\nğŸ”— URL: {url}\"\n",
        "                print(f\"\\n{'â˜…'*50}\\n{msg}\\n{'â˜…'*50}\\n\")\n",
        "                send_discord(msg)\n",
        "                break\n",
        "            sock.close()\n",
        "        except: pass\n",
        "        time.sleep(5)\n",
        "\n",
        "threading.Thread(target=monitor_ready, args=(8188,), daemon=True).start()\n",
        "\n",
        "# ==========================================\n",
        "# ğŸš€ 5. èµ·å‹• (H100/A100 æœ€é€Ÿè¨­å®š)\n",
        "# ==========================================\n",
        "%cd /content/ComfyUI\n",
        "mem_flags = \"\" if any(x in gpu_name for x in [\"H100\", \"A100\"]) else \"--lowvram\"\n",
        "print(f\"ğŸš€ {gpu_name} æœ€é€Ÿãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™...\")\n",
        "!python main.py {mem_flags} --cache-none --dont-print-server"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, shutil\n",
        "\n",
        "# é…ç½®å…ˆã®å®šç¾©\n",
        "LORA_DIR = \"/content/ComfyUI/models/loras\"\n",
        "os.makedirs(LORA_DIR, exist_ok=True)\n",
        "\n",
        "# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæƒ…å ±\n",
        "repo = \"Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Left\"\n",
        "file = \"ltx-2-19b-lora-camera-control-dolly-left.safetensors\"\n",
        "dest_path = os.path.join(LORA_DIR, file)\n",
        "\n",
        "def final_piece_download():\n",
        "    if not os.path.exists(dest_path):\n",
        "        print(f\"ğŸ“¥ æœ€å¾Œã®ãƒ”ãƒ¼ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {file}...\")\n",
        "        # ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "        subprocess.run([\"hf\", \"download\", repo, file, \"--local-dir\", LORA_DIR, \"--quiet\"])\n",
        "        print(f\"âœ… é…ç½®å®Œäº†: {dest_path}\")\n",
        "    else:\n",
        "        print(f\"âœ… ã™ã§ã«å­˜åœ¨ã—ã¾ã™: {file}\")\n",
        "\n",
        "    print(\"\\nâœ¨ ã“ã‚Œã§ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæƒã„ã¾ã—ãŸï¼\")\n",
        "    print(\"ğŸš€ ComfyUI ã®ç”»é¢ã§ã€ŒRefreshã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€ç”Ÿæˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "final_piece_download()"
      ],
      "metadata": {
        "id": "7henXDh_RUfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ğŸ“Š ç¾åœ¨ã®ãƒ‡ã‚£ã‚¹ã‚¯ç©ºãå®¹é‡: 18GB\n",
        "âŒ å®¹é‡ä¸è¶³: æ®‹ã‚Š18GBã§ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã€‚\n",
        "ğŸ’¡ å¯¾ç­–: ä»–ã®å·¨å¤§ãª.safetensorsï¼ˆdev-fp8ç‰ˆãªã©ï¼‰ã‚’å‰Šé™¤ã—ã¦ç©ºãã‚’ä½œã£ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "IEjncBoVce6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, subprocess\n",
        "\n",
        "# ==========================================\n",
        "# ğŸ§¹ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºä¿ãƒ­ã‚¸ãƒƒã‚¯\n",
        "# ==========================================\n",
        "def swap_models_for_distilled():\n",
        "    base_path = \"/content/ComfyUI/models\"\n",
        "    dev_model = os.path.join(base_path, \"checkpoints/ltx-2-19b-dev-fp8.safetensors\")\n",
        "    distilled_model = os.path.join(base_path, \"checkpoints/ltx-2-19b-distilled.safetensors\")\n",
        "\n",
        "    # 1. è’¸ç•™ç‰ˆãŒãªã„å ´åˆã€Devç‰ˆã‚’å‰Šé™¤ã—ã¦å®¹é‡ã‚’ä½œã‚‹\n",
        "    if not os.path.exists(distilled_model):\n",
        "        if os.path.exists(dev_model):\n",
        "            print(f\"ğŸ§¹ å®¹é‡ç¢ºä¿ã®ãŸã‚ã€æ¨™æº–ç‰ˆã‚’å‰Šé™¤ã—ã¾ã™: {dev_model}\")\n",
        "            os.remove(dev_model)\n",
        "        else:\n",
        "            print(\"ğŸ’¡ æ¨™æº–ç‰ˆãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«å‰Šé™¤ã•ã‚Œã¦ã„ã‚‹ã‹ã€å­˜åœ¨ã—ã¾ã›ã‚“ã€‚\")\n",
        "\n",
        "    # 2. ä¸è¦ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å¼·åˆ¶æ’é™¤\n",
        "    !pip cache purge\n",
        "\n",
        "    total, used, free = shutil.disk_usage(\"/\")\n",
        "    free_gb = free // (2**30)\n",
        "    print(f\"ğŸ“Š ç¾åœ¨ã®ç©ºãå®¹é‡: {free_gb}GB\")\n",
        "\n",
        "    # 3. ä¸è¶³åˆ†ã®å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå®¹é‡ãƒã‚§ãƒƒã‚¯ä»˜ï¼‰\n",
        "    def safe_download(repo, file, folder, min_gb):\n",
        "        dest = os.path.join(folder, file)\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        if not os.path.exists(dest):\n",
        "            _, _, current_free = shutil.disk_usage(\"/\")\n",
        "            if (current_free // (2**30)) > min_gb:\n",
        "                print(f\"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {file}...\")\n",
        "                subprocess.run([\"hf\", \"download\", repo, file, \"--local-dir\", folder, \"--quiet\"])\n",
        "                print(f\"âœ… å®Œäº†: {file}\")\n",
        "            else:\n",
        "                print(f\"âŒ å®¹é‡ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {file} (æ®‹ã‚Š {current_free // (2**30)}GB)\")\n",
        "\n",
        "    # è’¸ç•™ç‰ˆæœ¬ä½“ (ç´„35GB)\n",
        "    safe_download(\"Lightricks/LTX-2\", \"ltx-2-19b-distilled.safetensors\", os.path.join(base_path, \"checkpoints\"), 36)\n",
        "    # ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼\n",
        "    safe_download(\"Lightricks/LTX-2\", \"ltx-2-spatial-upscaler-x2-1.0.safetensors\", os.path.join(base_path, \"latent_upscale_models\"), 2)\n",
        "    # ã‚«ãƒ¡ãƒ©LoRA\n",
        "    safe_download(\"Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Left\", \"ltx-2-19b-lora-camera-control-dolly-left.safetensors\", os.path.join(base_path, \"loras\"), 1)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "swap_models_for_distilled()"
      ],
      "metadata": {
        "id": "UwrrYLzEc-Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš¨ è­¦å‘Š: å¤±æ•—ã—ãŸå·¨å¤§ãªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ®‹éª¸ã‚’æ¶ˆå»ã—ã¦ãƒ‡ã‚£ã‚¹ã‚¯ã‚’ã€Œ70GBä»¥ä¸Šã€ç©ºã‘ã¾ã™\n",
        "!rm -rf /content/ComfyUI/models/checkpoints/*.safetensors\n",
        "!rm -rf /root/.cache/huggingface\n",
        "!pip cache purge\n",
        "import shutil\n",
        "print(f\"ğŸ“Š æƒé™¤å¾Œã®ç©ºãå®¹é‡: {shutil.disk_usage('/')[2] // (2**30)}GB\")"
      ],
      "metadata": {
        "id": "4Pi3A6g112vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # ğŸš€ LTX-2 FP8ç‰ˆ èµ·å‹•ã‚»ãƒ«ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ãƒ»URLè¡¨ç¤º ä¿®æ­£ç‰ˆï¼‰\n",
        "\n",
        "import os, socket, time, threading, requests, shutil, subprocess, re, sys\n",
        "from google.colab import userdata, output\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# --- è¨­å®š ---\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "webhook_url = userdata.get('DISCORD_URL')\n",
        "if hf_token: os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "def send_discord(msg):\n",
        "    if webhook_url:\n",
        "        try: requests.post(webhook_url, json={\"content\": msg}, timeout=10)\n",
        "        except: pass\n",
        "\n",
        "# --- URLè¡¨ç¤ºã‚’æœ€å„ªå…ˆã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ ---\n",
        "def monitor_url(port):\n",
        "    print(f\"ğŸ“¡ æ¥ç¶šå¾…ã¡... (Port {port})\")\n",
        "    while True:\n",
        "        try:\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            res = sock.connect_ex(('127.0.0.1', port))\n",
        "            sock.close()\n",
        "            if res == 0:\n",
        "                url = output.eval_js(f'google.colab.kernel.proxyPort({port})')\n",
        "                msg = f\"ğŸ‰ **ComfyUI èµ·å‹•å®Œäº†**\\nğŸ”— URL: {url}\"\n",
        "                print(f\"\\n{'â˜…'*40}\\n{msg}\\n{'â˜…'*40}\\n\")\n",
        "                send_discord(msg)\n",
        "                break\n",
        "        except: pass\n",
        "        time.sleep(2)\n",
        "\n",
        "# --- 1. ãƒ‡ã‚£ã‚¹ã‚¯ç¢ºèª & æœ€å°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---\n",
        "%cd /content\n",
        "if not os.path.exists(\"ComfyUI\"):\n",
        "    !git clone https://github.com/Comfy-Org/ComfyUI.git -q\n",
        "\n",
        "# å¿…é ˆãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼ˆFP8ç‰ˆ=19GBï¼‰\n",
        "print(\"ğŸ“¥ æœ€å°é™ã®ãƒ¢ãƒ‡ãƒ«(FP8)ã‚’ç¢ºèªä¸­...\")\n",
        "def hf_get(repo, file, folder):\n",
        "    dest = os.path.join(\"/content/ComfyUI\", folder, file)\n",
        "    if not os.path.exists(dest):\n",
        "        !hf download {repo} {file} --local-dir {\"/content/ComfyUI/\"+folder} --quiet\n",
        "\n",
        "# Gemma(12GB) + LTX2-FP8(19GB) = è¨ˆ31GB\n",
        "hf_get(\"Comfy-Org/ltx-2\", \"split_files/text_encoders/gemma_3_12B_it.safetensors\", \"models/text_encoders\")\n",
        "g_wrong = \"/content/ComfyUI/models/text_encoders/split_files/text_encoders/gemma_3_12B_it.safetensors\"\n",
        "if os.path.exists(g_wrong): shutil.move(g_wrong, \"/content/ComfyUI/models/text_encoders/gemma_3_12B_it.safetensors\")\n",
        "\n",
        "hf_get(\"Lightricks/LTX-2\", \"ltx-2-19b-dev-fp8.safetensors\", \"models/checkpoints\")\n",
        "\n",
        "# --- 2. ã‚µãƒ¼ãƒãƒ¼èµ·å‹• ---\n",
        "threading.Thread(target=monitor_url, args=(8188,), daemon=True).start()\n",
        "%cd /content/ComfyUI\n",
        "print(\"ğŸš€ ã‚µãƒ¼ãƒãƒ¼ã‚’ç«‹ã¡ä¸Šã’ã¾ã™...\")\n",
        "!python main.py --cache-none --dont-print-server"
      ],
      "metadata": {
        "id": "lGjlhBmD1-Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9g1j5mlsc-DU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeqjdDwGdOH4"
      },
      "source": [
        "# æŠ€è¡“çš„ãªæ”¹å–„ç‚¹ã¾ã¨ã‚\n",
        "## æŠ€è¡“è§£èª¬ï¼š2026å¹´ç‰ˆ LTX-2 é‹ç”¨ã‚¬ã‚¤ãƒ‰\n",
        "\n",
        "ã“ã®ç’°å¢ƒã§ã¯ã€ä»¥ä¸‹ã®é«˜åº¦ãªæœ€é©åŒ–ãŒæ–½ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "VRAM ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ: A100 80GB ã§ã¯ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’ VRAM ã«ä¿æŒã™ã‚‹é«˜é€Ÿæ¨è«–ã‚’ã€L4 22.5GB ã§ã¯ --lowvram ã‚’ç”¨ã„ãŸå …å®Ÿãªå‹•ä½œã‚’è‡ªå‹•çš„ã«é¸æŠã—ã¾ã™ã€‚\n",
        "\n",
        "ã‚¢ã‚»ãƒƒãƒˆä¸æ•´åˆã®è§£æ¶ˆ: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¦æ±‚ã™ã‚‹ woman_with_paper ç³»ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€ç¾åœ¨ã®æ­£ã—ã„é…å¸ƒURLã‹ã‚‰è‡ªå‹•å–å¾—ã—ã¾ã™ã€‚\n",
        "\n",
        "ãƒãƒ«ãƒãƒªãƒã‚¸ãƒˆãƒªãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: å˜ä¸€ã®é…å¸ƒå…ƒã§ã¯æƒã‚ãªã„ Pose Control LoRA ã‚„ Text Encoder ã‚’ã€è¤‡æ•°ã® Hugging Face ãƒªãƒã‚¸ãƒˆãƒªã‚’æ¨ªæ–­ã—ã¦ä¸€æ‹¬ã§æƒãˆã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã§ã€æº–å‚™ã¯ä¸‡å…¨ã§ã™ã€‚æä¾›ã•ã‚ŒãŸ JSON ãƒ•ã‚¡ã‚¤ãƒ« ã‚’èª­ã¿è¾¼ã¿ã€LTX-2 ã®é©šç•°çš„ãªå‹•ç”»ç”Ÿæˆèƒ½åŠ›ã‚’ã”ä½“é¨“ãã ã•ã„ï¼\n",
        "\n",
        "\n",
        "ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®ã€Œè¦‹ãˆã‚‹åŒ–ã€: æº–å‚™å®Œäº†é€šçŸ¥ã«ç¾åœ¨ã®ãƒ‡ã‚£ã‚¹ã‚¯æ®‹é‡ã‚’è¨˜è¼‰ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ã¨ã©ã‚Œãã‚‰ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã§ãã‚‹ã‹ä¸€ç›®ã§åˆ†ã‹ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: safe_hf_get é–¢æ•°ãŒã€Google Colabã®ãƒ‡ã‚£ã‚¹ã‚¯æ®‹é‡ã‚’1ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚ã‚‚ã— 35GB ã® Distilled ãƒ¢ãƒ‡ãƒ«ã‚’å…¥ã‚Œã‚ˆã†ã¨ã—ã¦æ®‹ã‚ŠãŒ 20GB ã—ã‹ãªã‘ã‚Œã°ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦Discordã«è­¦å‘Šã‚’é€ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã®è‡ªå·±è¨ºæ–­: ãƒ­ã‚°ã« FileNotFoundError (ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸å¯) ãŒå‡ºãŸå ´åˆã€ä»Šå›ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Œãƒ‡ã‚£ã‚¹ã‚¯ãƒ‘ãƒ³ã‚¯ã€ã¨å³åº§ã«åˆ¤å®šã—ã¦Discordã«å ±å‘Šã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã§ã€Œã„ã¤ã®é–“ã«ã‹ãƒ‡ã‚£ã‚¹ã‚¯ãŒã„ã£ã±ã„ã§å‹•ã‹ãªããªã£ã¦ã„ãŸã€ã¨ã„ã†äº‹æ…‹ã‚’æœªç„¶ã«é˜²ã’ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã¾ãšã¯å®Ÿè¡Œã—ã¦ã€æ®‹é‡ãŒä½•GBã¨è¡¨ç¤ºã•ã‚Œã‚‹ã‹ç¢ºèªã—ã¦ã¿ã¦ãã ã•ã„\n",
        "\n",
        "\n",
        "# è¬è¾ï¼šã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ AICU Japan ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã—ã¦ãŠã‚Šã¾ã™ã€‚è³ªå•ã¯ [X@AICUai](https://x.com/AICUai) ã¾ã§ã€‚"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}